{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c633531-83f6-47bd-b1ee-1f448b4393d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lab Exercise 2: Learning Basics of Regularization\n",
    "This exercise provides a comprehensive introduction to regularization, combining theoretical concepts with practical implementation and evaluation.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "The goal of this lab exercise is to understand the fundamentals of regularization, a technique used to prevent overfitting in machine learning models. You will learn how to implement and evaluate regularization techniques such as Ridge (L2) and Lasso (L1) regression.\n",
    "\n",
    "**Prerequisites**\n",
    "- Basic knowledge of Python programming\n",
    "- Basic understanding of linear regression\n",
    "- Familiarity with numpy, pandas, scikit-learn, and matplotlib libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5445b1-211c-4647-932e-fdb773a3b7fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Part 1: Understanding the Theory\n",
    "**Introduction to Regularization**\n",
    "\n",
    "Regularization techniques are used to add a penalty to the model complexity, helping to prevent overfitting. The most common regularization techniques are Ridge (L2) and Lasso (L1) regression.\n",
    "\n",
    "**Key Concepts**\n",
    "- Ridge Regression (L2): Adds the squared magnitude of coefficients as a penalty term to the loss function.\n",
    "- Lasso Regression (L1): Adds the absolute value of coefficients as a penalty term to the loss function, which can lead to sparse models with some coefficients set to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd6e79-5434-4a3e-b111-070707636a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Part 2: Implementing Regularization\n",
    "*Step 1: Generate Synthetic Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21059c-6a77-46e3-bcff-060867676803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate synthetic dataset\n",
    "num_samples = 100\n",
    "num_features = 10\n",
    "\n",
    "X = np.random.rand(num_samples, num_features)\n",
    "true_coefficients = np.random.randn(num_features)\n",
    "y = X.dot(true_coefficients) + 0.5 * np.random.randn(num_samples)\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "feature_names = [f'Feature_{i+1}' for i in range(num_features)]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['Target'] = y\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab59525-38e9-4625-a627-3c69c82bacdc",
   "metadata": {},
   "source": [
    "*Step 2: Split the Data into Training and Test Sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456bb280-373d-416f-a9eb-185710acfd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[feature_names], df['Target'], test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5720f-ab66-4cde-b123-78ccd2fdfea1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Part 3: Applying Regularization Techniques\n",
    "*Step 3: Ridge Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75262201-ab78-44d0-9be9-87ef85402e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the Ridge regression model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate mean squared error\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "print(f'MSE using Ridge regression: {mse_ridge:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce44bb2-c0e3-47ab-942c-fe9a94d417ac",
   "metadata": {},
   "source": [
    "*Step 4: Lasso Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3952a-f499-4a8e-a216-02b7830d8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize the Lasso regression model\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate mean squared error\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "\n",
    "print(f'MSE using Lasso regression: {mse_lasso:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc30abc-ba0a-4346-adeb-e0a94887c219",
   "metadata": {},
   "source": [
    "*Step 5: Compare with Ordinary Least Squares (OLS)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640cd40-6fe5-4f90-b1a1-b776f8f4e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the OLS regression model\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate mean squared error\n",
    "y_pred_ols = ols.predict(X_test)\n",
    "mse_ols = mean_squared_error(y_test, y_pred_ols)\n",
    "\n",
    "print(f'MSE using OLS regression: {mse_ols:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02711442-d0e6-44a2-8478-0cd449835f13",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Part 4: Evaluating and Visualizing Results\n",
    "*Step 6: Compare Coefficients*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9865a92-dc3a-44b9-8f6a-d5588c2144cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the coefficients from each model\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'OLS': ols.coef_,\n",
    "    'Ridge': ridge.coef_,\n",
    "    'Lasso': lasso.coef_\n",
    "})\n",
    "\n",
    "print(coefficients_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c1a1a-4bcc-43a7-af52-43fb997892cb",
   "metadata": {},
   "source": [
    "*Step 7: Plot Coefficients*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e3c62-8258-4bef-ad20-260887601f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the coefficients\n",
    "coefficients_df.set_index('Feature').plot(kind='bar', figsize=(12, 8))\n",
    "plt.title('Comparison of Coefficients')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164078fb-ec0a-4803-be03-5039d2a2c05c",
   "metadata": {},
   "source": [
    "*Step 8: Plot Residuals*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd42084-5323-4c6d-a293-743436223db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals for each model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(y_test, y_test - y_pred_ols, label='OLS Residuals')\n",
    "plt.scatter(y_test, y_test - y_pred_ridge, label='Ridge Residuals')\n",
    "plt.scatter(y_test, y_test - y_pred_lasso, label='Lasso Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc76bd4-15f1-4089-9d63-d3e738466506",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Conclusion\n",
    "In this lab exercise, you learned the basics of regularization by:\n",
    "\n",
    "1. Generating a synthetic dataset.\n",
    "2. Applying Ridge (L2) and Lasso (L1) regression.\n",
    "3. Comparing the performance and coefficients of regularized models with OLS regression.\n",
    "4. Visualizing the results and residuals.\n",
    "\n",
    "Feel free to experiment with different regularization parameters and observe how they affect the model performance and coefficients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
